# üöÄ LLM-WebApp para Modelos de Gemini AI personalizados

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)
![Google Gemini](https://img.shields.io/badge/Google_Gemini-8E44AD?style=for-the-badge&logo=google&logoColor=white)
![HTML5](https://img.shields.io/badge/HTML5-E34F26?style=for-the-badge&logo=html5&logoColor=white)
![CSS3](https://img.shields.io/badge/CSS3-1572B6?style=for-the-badge&logo=css3&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Heroku](https://img.shields.io/badge/Heroku-430098?style=for-the-badge&logo=heroku&logoColor=white)

Una interfaz web din√°mica e intuitiva para interactuar con los potentes modelos de IA de Google Gemini. Chatea, personaliza par√°metros y obt√©n respuestas contextualizadas basadas en el contenido de tus propios archivos PDF, todo directamente desde tu navegador.



## ‚ú® Caracter√≠sticas Principales

-   **üöÄ Selecci√≥n de Modelos de Vanguardia:** Elige entre las versiones m√°s recientes de Gemini: `gemini-2.5-pro`, `gemini-2.5-flash` y `gemini-2.5-flash-lite`.
-   **‚öôÔ∏è Control Total sobre los Par√°metros:** Ajusta con precisi√≥n la `temperatura`, `top-p`, `top-k` y el m√°ximo de `tokens` para moldear la creatividad y exactitud de la IA.
-   **üìÑ Chat con tus Documentos (PDF):** Carga un archivo PDF y la IA lo usar√° como base de conocimiento para responder tus preguntas de forma contextualizada.
-   **üí¨ Interfaz de Chat Moderna:** Una experiencia de usuario limpia, responsiva y agradable para mantener conversaciones fluidas.
-   **üëÅ Renderizado de Markdown:** Las respuestas de la IA se muestran con formato Markdown, permitiendo una f√°cil lectura de listas, c√≥digo, tablas y m√°s.
-   **‚ö° Arquitectura 100% Client-Side:** Toda la l√≥gica se ejecuta en tu navegador. No se necesita un backend, lo que garantiza privacidad y rapidez.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

-   **Python:** Para realizar pruebas de llamada de API y ajustes de par√°metros de los modelos.
-   **HTML5:** Para la estructura sem√°ntica del contenido.
-   **CSS3:** Para el dise√±o y la apariencia visual.
-   **JavaScript (Vanilla):** Para toda la l√≥gica interactiva y la comunicaci√≥n con la API.
-   **Google AI JavaScript SDK:** Para la integraci√≥n directa con los modelos de Gemini.
-   **Marked.js:** Una librer√≠a ligera para renderizar Markdown en el cliente.
-   **pdf.js:** Para extraer el texto de los archivos PDF directamente en el navegador.
-   **Docker:** Para la contenedorizaci√≥n de la aplicaci√≥n.
-   **Heroku:** Para el despliegue de la aplicaci√≥n en la nube.

## üèÅ C√≥mo Empezar

Para ejecutar este proyecto en tu m√°quina local, sigue estos sencillos pasos.

### Requisitos Previos

Aseg√∫rate de tener:
1.  Un navegador web moderno (Chrome, Firefox, Edge).
2.  Tu propia **Clave API de Google Gemini**. Puedes obtener una en [Google AI Studio](https://aistudio.google.com/app/apikey).

### Instalaci√≥n

1.  **Clona el repositorio:**
    ```bash
    git repo clone facuberon/LLM-WebApp
    ```
2.  **Navega al directorio del proyecto:**
    ```bash
    cd LLM-WebApp
    ```
3.  **Abre el archivo `index.html` en tu navegador.**
    ¬°Y eso es todo! La aplicaci√≥n est√° lista para usarse.

## üìñ Gu√≠a de Uso

1.  üîë **Ingresa tu Clave API:** Pega tu clave API de Gemini en el campo correspondiente.
2.  ü§ñ **Elige un Modelo:** Selecciona el modelo de IA que desees utilizar en el men√∫ desplegable.
3.  üìÑ **Sube un PDF (Opcional):** Haz clic en "Elegir Archivo" para seleccionar un PDF. La IA usar√° su contenido como contexto.
4.  üéõÔ∏è **Ajusta los Par√°metros:** Modifica los deslizadores de `temperatura`, `top-p`, etc., seg√∫n tus necesidades.
5.  ‚ñ∂Ô∏è **Inicia la Conversaci√≥n:** Presiona el bot√≥n "Iniciar Chat".
6.  ‚å®Ô∏è **Env√≠a Mensajes:** Escribe tu pregunta en el campo de texto y presiona `Enter` o el bot√≥n "Enviar".
7.  üîÑ **Reinicia el Chat:** Si quieres empezar de nuevo, haz clic en "Reiniciar Chat" para volver a la pantalla de configuraci√≥n.

## üê≥ Dockerizaci√≥n y Deploy

Esta aplicaci√≥n ha sido dockerizada para facilitar su despliegue y ejecuci√≥n en cualquier entorno compatible con Docker.

### Ejecuci√≥n con Docker

1.  **Construir la imagen de Docker:**
    ```bash
    docker build -t llm-webapp .
    ```
2.  **Ejecutar el contenedor:**
    ```bash
    docker run -d -p 8080:80 llm-webapp
    ```
    La aplicaci√≥n estar√° disponible en `http://localhost:8080`.

### Despliegue en Heroku

La aplicaci√≥n est√° lista para ser desplegada en Heroku utilizando el stack de contenedores de Heroku. Con el `Dockerfile` y el `Procfile` configurados, puedes desplegar la aplicaci√≥n siguiendo la [gu√≠a de Heroku para contenedores](https://devcenter.heroku.com/articles/container-registry-and-runtime).

## üí° Pr√≥ximas Mejoras

Este proyecto est√° en constante evoluci√≥n. Algunas ideas para el futuro incluyen:
-   [ ] Historial de conversaciones persistente (usando `localStorage`).
-   [ ] Soporte para m√°s formatos de archivo ( `.txt`, `.md`, `.docx`).
-   [ ] Opci√≥n para exportar la conversaci√≥n.
-   [ ] Mejoras en la interfaz de usuario y animaciones.
